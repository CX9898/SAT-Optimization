GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 32,
        "max_seq_len": 2048,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 64,
        "batch_size": 32,
        "density": 0.04,
        "mixed_precision": true,
        "random_seed": 7,
        "task": "lra-listops"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0006,
        "warmup": 1000,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 1000,
        "num_eval_steps": 62,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(32, 64)
        (position_embeddings): Embedding(2048, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([32, 64]), torch.Size([2048, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 280842
Loaded ../Skyformer/data/lra_processed/lra-listops.train.pickle... size=96000
Loaded ../Skyformer/data/lra_processed/lra-listops.dev.pickle... size=2000
Loaded ../Skyformer/data/lra_processed/lra-listops.test.pickle... size=2000
accumu_steps=1
[tensor([35.6981, 35.6981, 35.6980, 35.6981], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([34.4797, 34.4797, 34.4797, 34.4797], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([35.1026, 35.1026, 35.1026, 35.1026], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([37.7804, 37.7804, 37.7804, 37.7804], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.1602, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 2.25827
Valid Accuracy: 0.16016
time stamp: 828.6918315887451
[tensor([9.8549, 9.8549, 9.8549, 9.8549], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.4704, 9.4704, 9.4704, 9.4704], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.6713, 9.6713, 9.6713, 9.6713], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.5236, 10.5236, 10.5236, 10.5236], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.3599, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.73248
Valid Accuracy: 0.35988
time stamp: 1660.6341228485107
[tensor([3.2025, 3.2025, 3.2025, 3.2025], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.0807, 3.0807, 3.0807, 3.0807], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.1392, 3.1392, 3.1392, 3.1392], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.4243, 3.4243, 3.4243, 3.4243], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 1499
Valid Loss: 1.72654
Valid Accuracy: 0.35585
time stamp: 2499.5669956207275
[tensor([1.4790, 1.4790, 1.4790, 1.4790], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4290, 1.4290, 1.4290, 1.4290], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4471, 1.4471, 1.4471, 1.4470], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.5760, 1.5760, 1.5760, 1.5760], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 1999
Valid Loss: 1.71716
Valid Accuracy: 0.35421
time stamp: 3349.6201510429382
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-listops/module.model.transformer_0.mha.pattern.pickle
tensor([ 660,  462,    0,  858,   66,  825,  132,  231,  495,  561,  990,  693,
         726,  297,  792,  396,  165,  330,  363,  429,  198,  957,  891,  924,
         528,   33,   99,  627,  759,  264, 1023,  477,  942,  594,  302,  457,
          62,  961,   73,  290], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_1.mha.pattern.pickle
tensor([ 363,  924,  957,  825,  396,  495,  627,    0,  165,  429,  264,  198,
         231,  660,  528,  561,  594, 1023,  726,  891,  462,  693,  792,  297,
         990,  132,   66,  330,  759,  858,   99,   33,  925,  956,  380,  907,
         496,  527,  284,  904], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_2.mha.pattern.pickle
tensor([ 429,  990,   33,  462,  792,  363,  231,  726,  528,  825,   99,  495,
         165,  693,  759,    0,  561, 1023,  330,  891,  858,  924,  627,  264,
         396,  297,  957,  132,  660,  198,  594,   66,  367,  491,   13,  416,
          43,  353,   57,  801], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_3.mha.pattern.pickle
tensor([ 594,   99,  165,  462, 1023,  396,  561,  693,  264,  759,   33,  858,
         528,  792,  924,  330,  825,  891,  297,  132,  231,  660,  957,  495,
         429,    0,  198,  363,  726,  990,   66,  627,   21,  672,  701,  949,
         602,  850,  703, 1013], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.11994481086730957
[]

Validation Results
Global Steps: 2499
Valid Loss: 2.17612
Valid Accuracy: 0.24609
time stamp: 4170.6362981796265
[]

Validation Results
Global Steps: 2999
Valid Loss: 1.75836
Valid Accuracy: 0.35018
time stamp: 4215.983680486679
[]
best model saved: step =  3499 dev accu =  tensor(0.3635, device='cuda:0')

Validation Results
Global Steps: 3499
Valid Loss: 1.72729
Valid Accuracy: 0.36353
time stamp: 4261.427152633667
[]

Validation Results
Global Steps: 3999
Valid Loss: 1.71298
Valid Accuracy: 0.35509
time stamp: 4307.40526509285
[]

Validation Results
Global Steps: 4499
Valid Loss: 1.69460
Valid Accuracy: 0.35433
time stamp: 4353.160885334015
[]

Validation Results
Global Steps: 4999
Valid Loss: 1.67080
Valid Accuracy: 0.35509
time stamp: 4398.984356880188
[]
best model saved: step =  5499 dev accu =  tensor(0.3643, device='cuda:0')

Validation Results
Global Steps: 5499
Valid Loss: 1.67236
Valid Accuracy: 0.36429
time stamp: 4445.213317632675
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.65880
Valid Accuracy: 0.36013
time stamp: 4491.135185718536
[]

Validation Results
Global Steps: 6499
Valid Loss: 1.65411
Valid Accuracy: 0.35446
time stamp: 4537.130575418472
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.64182
Valid Accuracy: 0.35736
time stamp: 4583.048618793488
[]

Validation Results
Global Steps: 7499
Valid Loss: 1.64514
Valid Accuracy: 0.35534
time stamp: 4628.560917139053
[]

Validation Results
Global Steps: 7999
Valid Loss: 1.64523
Valid Accuracy: 0.35156
time stamp: 4673.820242166519
[]

Validation Results
Global Steps: 8499
Valid Loss: 1.63962
Valid Accuracy: 0.35622
time stamp: 4719.8496770858765
[]

Validation Results
Global Steps: 8999
Valid Loss: 1.64058
Valid Accuracy: 0.35345
time stamp: 4764.636143684387
[]
best model saved: step =  9499 dev accu =  tensor(0.3667, device='cuda:0')

Validation Results
Global Steps: 9499
Valid Loss: 1.63890
Valid Accuracy: 0.36668
time stamp: 4810.174953699112
[]

Validation Results
Global Steps: 9999
Valid Loss: 1.63457
Valid Accuracy: 0.35963
time stamp: 4856.389292955399
total training step (k): 10.0
total training time (s): 4856.389920949936
total training time (ms): 64266.53125
peak memory usage (MB): 12399
allocated memory usage (MB): 122657072
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7572 KB |   12399 MB |  119782 GB |  119782 GB |
|       from large pool |    3145 KB |   12391 MB |  119264 GB |  119264 GB |
|       from small pool |    4427 KB |      13 MB |     518 GB |     518 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7572 KB |   12399 MB |  119782 GB |  119782 GB |
|       from large pool |    3145 KB |   12391 MB |  119264 GB |  119264 GB |
|       from small pool |    4427 KB |      13 MB |     518 GB |     518 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   13530 MB |   13530 MB |   13530 MB |       0 B  |
|       from large pool |   13516 MB |   13516 MB |   13516 MB |       0 B  |
|       from small pool |      14 MB |      14 MB |      14 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1038 MB |    2041 MB |   42188 GB |   42187 GB |
|       from large pool |    1036 MB |    2036 MB |   41601 GB |   41600 GB |
|       from small pool |       1 MB |       7 MB |     587 GB |     587 GB |
|---------------------------------------------------------------------------|
| Allocations           |     246    |     407    |    9186 K  |    9185 K  |
|       from large pool |       2    |      93    |    3529 K  |    3529 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     246    |     407    |    9186 K  |    9185 K  |
|       from large pool |       2    |      93    |    3529 K  |    3529 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      25    |      25    |      25    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      11    |      32    |    5095 K  |    5095 K  |
|       from large pool |       3    |      18    |    1867 K  |    1867 K  |
|       from small pool |       8    |      23    |    3227 K  |    3227 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-7/lra-listops/learnable.model
Evaluation Results
Loss: 1.60780
Accuracy: 0.38333
