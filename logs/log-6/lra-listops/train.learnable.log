GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 32,
        "max_seq_len": 2048,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 64,
        "batch_size": 32,
        "density": 0.04,
        "mixed_precision": true,
        "random_seed": 6,
        "task": "lra-listops"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0006,
        "warmup": 1000,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 1000,
        "num_eval_steps": 62,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(32, 64)
        (position_embeddings): Embedding(2048, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([32, 64]), torch.Size([2048, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 280842
Loaded ../Skyformer/data/lra_processed/lra-listops.train.pickle... size=96000
Loaded ../Skyformer/data/lra_processed/lra-listops.dev.pickle... size=2000
Loaded ../Skyformer/data/lra_processed/lra-listops.test.pickle... size=2000
accumu_steps=1
[tensor([33.5252, 33.5252, 33.5252, 33.5252], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([37.2226, 37.2226, 37.2226, 37.2226], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([37.6706, 37.6706, 37.6705, 37.6706], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([42.1075, 42.1075, 42.1075, 42.1075], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.1788, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 2.26087
Valid Accuracy: 0.17881
time stamp: 830.3026115894318
[tensor([9.1218, 9.1218, 9.1218, 9.1218], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.3282, 10.3282, 10.3282, 10.3282], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.4339, 10.4339, 10.4338, 10.4339], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([11.8993, 11.8993, 11.8993, 11.8993], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.3569, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.73224
Valid Accuracy: 0.35685
time stamp: 1658.9009494781494
[tensor([2.9445, 2.9445, 2.9445, 2.9445], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.3602, 3.3602, 3.3602, 3.3602], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.3699, 3.3699, 3.3699, 3.3699], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.8463, 3.8463, 3.8463, 3.8463], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1499 dev accu =  tensor(0.3603, device='cuda:0')

Validation Results
Global Steps: 1499
Valid Loss: 1.72941
Valid Accuracy: 0.36026
time stamp: 2490.3571887016296
[tensor([1.3581, 1.3581, 1.3581, 1.3581], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.5509, 1.5509, 1.5509, 1.5509], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.5402, 1.5402, 1.5402, 1.5402], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.7350, 1.7350, 1.7350, 1.7350], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1999 dev accu =  tensor(0.3648, device='cuda:0')

Validation Results
Global Steps: 1999
Valid Loss: 1.72756
Valid Accuracy: 0.36479
time stamp: 3324.0424313545227
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-listops/module.model.transformer_0.mha.pattern.pickle
tensor([  66,  528,   99,  495,  594,  825,  891,  396,  957,  198,  627,  330,
         990,  759,  462,  165, 1023,  924,  858,  132,  297,  726,  363,  429,
           0,  561,  264,  693,  660,   33,  176,  517,  115,  611,  231,  496,
         527,   80,  514,  792], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_1.mha.pattern.pickle
tensor([ 627,  924,  231,  792,  825,  891,  660,  561,  990,  759,   99,  726,
         396, 1023,  462,  528,  297,  363,   66,  198,  132,  693,   33,  264,
           0,  957,  495,  858,  251,  871,  165,  594,  429,    9,  288,  330,
         761,  823,  283,  872], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_2.mha.pattern.pickle
tensor([ 627,  528,  231,    0,  759,  297,   66,  825,  396,  198,  726,  429,
        1023,   33,  495,  132,  792,  660,  924,  330,  462,  990,  858,  561,
          99,  594,  693,  957,  264,  363,  165,  891,  631,  755,   30,  960,
           7,  224,  476,  910], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_3.mha.pattern.pickle
tensor([ 165,  891,  330,  594,  858,   66,  462,  363,  495,  957,  726,  660,
         627,   33,  429, 1023,  198,  528,  297,  990,   99,  231,  264,    0,
         924,  693,  759,  396,  792,  132,  825,  174,  453,  101,  163,  187,
         869,  234,  327,  498], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.12117266654968262
[]

Validation Results
Global Steps: 2499
Valid Loss: 1.79031
Valid Accuracy: 0.35887
time stamp: 3508.346287727356
[]

Validation Results
Global Steps: 2999
Valid Loss: 1.74495
Valid Accuracy: 0.35295
time stamp: 3554.350301504135
[]

Validation Results
Global Steps: 3499
Valid Loss: 1.73745
Valid Accuracy: 0.36265
time stamp: 3599.883521080017
[]

Validation Results
Global Steps: 3999
Valid Loss: 1.73205
Valid Accuracy: 0.35496
time stamp: 3645.1649980545044
[]

Validation Results
Global Steps: 4499
Valid Loss: 1.72743
Valid Accuracy: 0.35194
time stamp: 3690.7124989032745
[]

Validation Results
Global Steps: 4999
Valid Loss: 1.72300
Valid Accuracy: 0.35925
time stamp: 3736.7361721992493
[]

Validation Results
Global Steps: 5499
Valid Loss: 1.71136
Valid Accuracy: 0.35156
time stamp: 3782.18252825737
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.70874
Valid Accuracy: 0.35522
time stamp: 3827.9733893871307
[]

Validation Results
Global Steps: 6499
Valid Loss: 1.69005
Valid Accuracy: 0.36152
time stamp: 3873.5853939056396
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.66623
Valid Accuracy: 0.35849
time stamp: 3919.380795240402
[]

Validation Results
Global Steps: 7499
Valid Loss: 1.66769
Valid Accuracy: 0.35156
time stamp: 3965.458108663559
[]

Validation Results
Global Steps: 7999
Valid Loss: 1.66357
Valid Accuracy: 0.35673
time stamp: 4011.1171927452087
[]

Validation Results
Global Steps: 8499
Valid Loss: 1.66535
Valid Accuracy: 0.35824
time stamp: 4057.172477722168
[]

Validation Results
Global Steps: 8999
Valid Loss: 1.66397
Valid Accuracy: 0.35862
time stamp: 4103.440243721008
[]

Validation Results
Global Steps: 9499
Valid Loss: 1.66192
Valid Accuracy: 0.35786
time stamp: 4149.321753501892
[]

Validation Results
Global Steps: 9999
Valid Loss: 1.65750
Valid Accuracy: 0.35824
time stamp: 4194.659398555756
total training step (k): 10.0
total training time (s): 4194.660075426102
total training time (ms): 64394.52783203125
peak memory usage (MB): 12399
allocated memory usage (MB): 111671424
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7572 KB |   12399 MB |  109054 GB |  109054 GB |
|       from large pool |    3145 KB |   12391 MB |  108536 GB |  108536 GB |
|       from small pool |    4427 KB |      13 MB |     517 GB |     517 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7572 KB |   12399 MB |  109054 GB |  109054 GB |
|       from large pool |    3145 KB |   12391 MB |  108536 GB |  108536 GB |
|       from small pool |    4427 KB |      13 MB |     517 GB |     517 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   13530 MB |   13530 MB |   13530 MB |       0 B  |
|       from large pool |   13516 MB |   13516 MB |   13516 MB |       0 B  |
|       from small pool |      14 MB |      14 MB |      14 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1040 MB |    2041 MB |   42399 GB |   42398 GB |
|       from large pool |    1036 MB |    2036 MB |   41836 GB |   41835 GB |
|       from small pool |       3 MB |       7 MB |     562 GB |     562 GB |
|---------------------------------------------------------------------------|
| Allocations           |     246    |     407    |    9182 K  |    9181 K  |
|       from large pool |       2    |      93    |    3526 K  |    3526 K  |
|       from small pool |     244    |     381    |    5655 K  |    5655 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     246    |     407    |    9182 K  |    9181 K  |
|       from large pool |       2    |      93    |    3526 K  |    3526 K  |
|       from small pool |     244    |     381    |    5655 K  |    5655 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      25    |      25    |      25    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      12    |      33    |    4913 K  |    4913 K  |
|       from large pool |       3    |      18    |    1866 K  |    1866 K  |
|       from small pool |       9    |      25    |    3047 K  |    3047 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-6/lra-listops/learnable.model
Evaluation Results
Loss: 2.98729
Accuracy: 0.09896
