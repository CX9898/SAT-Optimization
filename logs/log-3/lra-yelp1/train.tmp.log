GPU list: [0]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 512,
        "max_seq_len": 1024,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 2,
        "block_size": 32,
        "batch_size": 128,
        "density": 0.05,
        "mixed_precision": true,
        "random_seed": 3,
        "task": "lra-yelp1"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0007,
        "warmup": 80,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 200,
        "num_train_steps": 30000,
        "num_init_steps": 17000,
        "num_eval_steps": 200,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01,
        "skewness": 1.7,
        "distance": 1.3
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(512, 64)
        (position_embeddings): Embedding(1024, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=2, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([512, 64]), torch.Size([1024, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([2, 128]), torch.Size([2])]
num_parameter: 244994
Loaded ../Skyformer/data/lra_processed/lra-yelp1.train.pickle... size=560000
Loaded ../Skyformer/data/lra_processed/lra-yelp1.dev.pickle... size=38000
Loaded ../Skyformer/data/lra_processed/lra-yelp1.test.pickle... size=38000
accumu_steps=1
[tensor(29.9131, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(32.3726, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(28.5765, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(30.4274, device='cuda:0', grad_fn=<MseLossBackward0>)]
best model saved: step =  199 dev accu =  tensor(0.6746, device='cuda:0')

Validation Results
Global Steps: 199
Valid Loss: 0.59270
Valid Accuracy: 0.67461
time stamp: 104.54843163490295
[tensor(12.9991, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(14.1485, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(12.3424, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(13.2770, device='cuda:0', grad_fn=<MseLossBackward0>)]
best model saved: step =  399 dev accu =  tensor(0.7109, device='cuda:0')

Validation Results
Global Steps: 399
Valid Loss: 0.56057
Valid Accuracy: 0.71094
time stamp: 209.54469323158264
[tensor(6.5431, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(7.1220, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(6.1948, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(6.7126, device='cuda:0', grad_fn=<MseLossBackward0>)]

Validation Results
Global Steps: 599
Valid Loss: 0.57136
Valid Accuracy: 0.70703
time stamp: 314.734739780426
[tensor(3.7002, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(4.0112, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(3.5024, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(3.8145, device='cuda:0', grad_fn=<MseLossBackward0>)]
best model saved: step =  799 dev accu =  tensor(0.7114, device='cuda:0')

Validation Results
Global Steps: 799
Valid Loss: 0.58020
Valid Accuracy: 0.71145
time stamp: 419.83408784866333
[tensor(2.2965, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(2.4723, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(2.1774, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(2.3795, device='cuda:0', grad_fn=<MseLossBackward0>)]
best model saved: step =  999 dev accu =  tensor(0.7274, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 0.53831
Valid Accuracy: 0.72742
time stamp: 525.1033318042755
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-yelp1/module.model.transformer_0.mha.pattern.pickle
tensor([ 198,  759,   99,  627,  957,  528,  594,  231,  924,   66,  363,  858,
         561,  495,  792,  825,   33,  990,  396,  429,  165,  132,  462, 1023,
         693,  891,  297,  726,  595,  626,  535,  752,  264,  210,  582,  330,
         111,  483,  536,  784,  765,  951,  240,  519,  497,  559,  958,  989,
         794,  856,  221], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-yelp1/module.model.transformer_1.mha.pattern.pickle
tensor([ 825,  396,   66,  528,    0,  462,  429,  495,  858,  627, 1023,  693,
          99,  264,  165,  726,  792,  231,  330,  363,  297,  957,  891,  561,
         660,  121,  803,   33,  594,  924,  990,  831, 1017,  403,  620,   12,
         384,  249,  807,   25,  800,  569,  817,  793,  824,  127,  995,   16,
         512,  239,  487], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-yelp1/module.model.transformer_2.mha.pattern.pickle
tensor([ 825,  891,   33,  165,  660,  363,  759,    0,  198,  264,  132,  231,
         462,  594,  330,  990,  627,  726,   99,  561,  429,  528,  924, 1023,
         396,  792,   66,  693,  297,  495,  858,  957,  183,  741,    1,   32,
         191,  997,  473,  814,  203,  358,   55,  737,  471,  750,  372,  651,
         465,  558,  727], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-yelp1/module.model.transformer_3.mha.pattern.pickle
tensor([ 759,  528,  363,  693,  924,  594,  396,   66,  990, 1023,  726,    0,
         297,  462,   33,  792,  429,  198,  957,   99,  165,  330,  627,  264,
         891,  825,  132,  858,  368,  523,  495,  561,  660,  380,  907,   22,
         704,  366,  459,  373,  683,  533,  688,   43,  353,  377,  811,   55,
         737,  364,  395], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.12124991416931152
total training step (k): 30.0
total training time (s): 526.58815574646
total training time (ms): 433148.3671875
peak memory usage (MB): 10632
allocated memory usage (MB): 46850934
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    4151 MB |   10632 MB |   45752 GB |   45748 GB |
|       from large pool |    4144 MB |   10604 MB |   45606 GB |   45602 GB |
|       from small pool |       7 MB |      32 MB |     146 GB |     146 GB |
|---------------------------------------------------------------------------|
| Active memory         |    4151 MB |   10632 MB |   45752 GB |   45748 GB |
|       from large pool |    4144 MB |   10604 MB |   45606 GB |   45602 GB |
|       from small pool |       7 MB |      32 MB |     146 GB |     146 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   10870 MB |   10870 MB |   10870 MB |       0 B  |
|       from large pool |   10836 MB |   10836 MB |   10836 MB |       0 B  |
|       from small pool |      34 MB |      34 MB |      34 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1078 MB |    1526 MB |    6862 GB |    6861 GB |
|       from large pool |    1072 MB |    1518 MB |    6713 GB |    6712 GB |
|       from small pool |       6 MB |      15 MB |     149 GB |     149 GB |
|---------------------------------------------------------------------------|
| Allocations           |     485    |     644    |    1153 K  |    1152 K  |
|       from large pool |      12    |      88    |     445 K  |     445 K  |
|       from small pool |     473    |     597    |     707 K  |     707 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     485    |     644    |    1153 K  |    1152 K  |
|       from large pool |      12    |      88    |     445 K  |     445 K  |
|       from small pool |     473    |     597    |     707 K  |     707 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      47    |      47    |      47    |       0    |
|       from large pool |      30    |      30    |      30    |       0    |
|       from small pool |      17    |      17    |      17    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      26    |      44    |  606438    |  606412    |
|       from large pool |       9    |      17    |  150253    |  150244    |
|       from small pool |      17    |      32    |  456185    |  456168    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

dense memory(MB) : {} 46740199
dense step : {} 1000
dense time : {} 525.2623612880707
sparse memory(MB) : {} 46846286
sparse step : {} 10
sparse_time : {} 1714026599.5239522
loading the best model from: ./checkpoints/checkpoints-3/lra-yelp1/tmp.model
