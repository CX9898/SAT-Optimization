GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 32,
        "max_seq_len": 2048,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 64,
        "batch_size": 32,
        "density": 0.04,
        "mixed_precision": true,
        "random_seed": 3,
        "task": "lra-listops"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0006,
        "warmup": 1000,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 1000,
        "num_eval_steps": 62,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(32, 64)
        (position_embeddings): Embedding(2048, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([32, 64]), torch.Size([2048, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 280842
Loaded ../Skyformer/data/lra_processed/lra-listops.train.pickle... size=96000
Loaded ../Skyformer/data/lra_processed/lra-listops.dev.pickle... size=2000
Loaded ../Skyformer/data/lra_processed/lra-listops.test.pickle... size=2000
accumu_steps=1
[tensor([34.9423, 34.9423, 34.9423, 34.9423], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([35.8196, 35.8197, 35.8196, 35.8196], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([40.9472, 40.9472, 40.9471, 40.9472], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([35.5194, 35.5194, 35.5194, 35.5194], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.1714, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 2.26263
Valid Accuracy: 0.17137
time stamp: 828.5881843566895
[tensor([9.5760, 9.5759, 9.5760, 9.5759], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.8698, 9.8698, 9.8698, 9.8698], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([11.5815, 11.5815, 11.5815, 11.5815], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.7805, 9.7805, 9.7804, 9.7805], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.3473, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.77768
Valid Accuracy: 0.34728
time stamp: 1659.988219499588
[tensor([3.1020, 3.1019, 3.1019, 3.1019], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.1906, 3.1906, 3.1905, 3.1905], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.7849, 3.7849, 3.7849, 3.7849], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.1693, 3.1693, 3.1693, 3.1693], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1499 dev accu =  tensor(0.3582, device='cuda:0')

Validation Results
Global Steps: 1499
Valid Loss: 1.77124
Valid Accuracy: 0.35824
time stamp: 2497.1816256046295
[tensor([1.4338, 1.4339, 1.4338, 1.4339], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4629, 1.4629, 1.4629, 1.4629], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.7345, 1.7345, 1.7345, 1.7345], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4596, 1.4596, 1.4596, 1.4596], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 1999
Valid Loss: 1.72618
Valid Accuracy: 0.34211
time stamp: 3339.273328065872
[tensor([0.8130, 0.8130, 0.8130, 0.8130], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.8214, 0.8214, 0.8214, 0.8214], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.9690, 0.9690, 0.9690, 0.9690], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.8237, 0.8237, 0.8237, 0.8237], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 2499
Valid Loss: 1.71435
Valid Accuracy: 0.35307
time stamp: 4186.760884523392
[tensor([0.5229, 0.5229, 0.5229, 0.5229], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.5237, 0.5238, 0.5237, 0.5237], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.6144, 0.6144, 0.6144, 0.6144], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.5278, 0.5278, 0.5278, 0.5278], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 2999
Valid Loss: 1.67926
Valid Accuracy: 0.35786
time stamp: 5037.435019254684
[tensor([0.3634, 0.3634, 0.3634, 0.3634], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.3618, 0.3618, 0.3618, 0.3618], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.4227, 0.4227, 0.4227, 0.4227], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.3661, 0.3661, 0.3661, 0.3661], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  3499 dev accu =  tensor(0.3661, device='cuda:0')

Validation Results
Global Steps: 3499
Valid Loss: 1.65931
Valid Accuracy: 0.36605
time stamp: 5895.815920114517
[tensor([0.2647, 0.2647, 0.2647, 0.2647], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.2626, 0.2626, 0.2626, 0.2626], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.3061, 0.3061, 0.3061, 0.3061], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.2667, 0.2667, 0.2667, 0.2667], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 3999
Valid Loss: 1.66139
Valid Accuracy: 0.35509
time stamp: 6755.878421545029
[tensor([0.1985, 0.1985, 0.1985, 0.1985], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.1966, 0.1966, 0.1966, 0.1966], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.2291, 0.2291, 0.2291, 0.2291], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.2002, 0.2002, 0.2002, 0.2002], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 4499
Valid Loss: 1.63196
Valid Accuracy: 0.36001
time stamp: 7617.88144826889
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-listops/module.model.transformer_0.mha.pattern.pickle
tensor([ 891,  198,  957,  561,  165,  462,  396,  297,  231,    0,   66,   33,
         825,  726,  132,  990,  627,  759,   99,  693,  528,  495,  924,  858,
         429,  594, 1023,  330,  363,  660,  264,  792,  187,  869,  146,  580,
         123,  867,  207,  486], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_1.mha.pattern.pickle
tensor([  33,  891,  759,  198,  330,  924,  429,  561,  594,  660,  627,   66,
         825,  132,  957,  495,  990,  363,  396,  297,  528,  231,  726,  792,
         165,  693, 1023,    0,  462,   99,  858,  264,  155,  868,  508,  911,
         375,  747,  211,  614], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_2.mha.pattern.pickle
tensor([ 231,  858,  924,  759,  528, 1023,  891,   66,  825,  957,  990,  198,
         396,    0,  330,   33,  132,  726,  363,  693,  561,   99,  495,  660,
         297,  264,  429,  462,  627,  165,  792,  594,  436,  653,  670,  980,
          72,  258,  240,  519], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_3.mha.pattern.pickle
tensor([ 594,   33,  132,  462,  363,  957,  990,  660, 1023,   66,  495,  264,
         693,  924,  330,  759,  726,    0,  561,  231,   99,  858,  297,  396,
         792,  528,  891,  627,  825,  165,  198,  429,  563,  625,  146,  580,
         466,  590,   22,  704], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.12273287773132324
[]

Validation Results
Global Steps: 4999
Valid Loss: 2.06370
Valid Accuracy: 0.30381
time stamp: 8315.516980409622
[]

Validation Results
Global Steps: 5499
Valid Loss: 1.75220
Valid Accuracy: 0.35421
time stamp: 8360.919895410538
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.69423
Valid Accuracy: 0.35610
time stamp: 8406.011034727097
[]
best model saved: step =  6499 dev accu =  tensor(0.3681, device='cuda:0')

Validation Results
Global Steps: 6499
Valid Loss: 1.66887
Valid Accuracy: 0.36807
time stamp: 8451.787669181824
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.66318
Valid Accuracy: 0.36517
time stamp: 8497.923768520355
[]

Validation Results
Global Steps: 7499
Valid Loss: 1.65950
Valid Accuracy: 0.36190
time stamp: 8543.695439815521
[]

Validation Results
Global Steps: 7999
Valid Loss: 1.65106
Valid Accuracy: 0.36139
time stamp: 8589.538319587708
[]

Validation Results
Global Steps: 8499
Valid Loss: 1.65253
Valid Accuracy: 0.36202
time stamp: 8634.715309858322
[]

Validation Results
Global Steps: 8999
Valid Loss: 1.64166
Valid Accuracy: 0.36505
time stamp: 8680.166519641876
[]

Validation Results
Global Steps: 9499
Valid Loss: 1.64672
Valid Accuracy: 0.36089
time stamp: 8725.31038236618
[]

Validation Results
Global Steps: 9999
Valid Loss: 1.64192
Valid Accuracy: 0.36227
time stamp: 8771.031175851822
total training step (k): 10.0
total training time (s): 8771.031655073166
total training time (ms): 91751.20458984375
peak memory usage (MB): 12399
allocated memory usage (MB): 192802846
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7572 KB |   12399 MB |  188284 GB |  188284 GB |
|       from large pool |    3145 KB |   12391 MB |  187759 GB |  187759 GB |
|       from small pool |    4427 KB |      13 MB |     524 GB |     524 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7572 KB |   12399 MB |  188284 GB |  188284 GB |
|       from large pool |    3145 KB |   12391 MB |  187759 GB |  187759 GB |
|       from small pool |    4427 KB |      13 MB |     524 GB |     524 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   13530 MB |   13530 MB |   13530 MB |       0 B  |
|       from large pool |   13516 MB |   13516 MB |   13516 MB |       0 B  |
|       from small pool |      14 MB |      14 MB |      14 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1040 MB |    2001 MB |   40505 GB |   40504 GB |
|       from large pool |    1036 MB |    1996 MB |   39926 GB |   39925 GB |
|       from small pool |       3 MB |       7 MB |     579 GB |     579 GB |
|---------------------------------------------------------------------------|
| Allocations           |     246    |     407    |    9201 K  |    9200 K  |
|       from large pool |       2    |      93    |    3544 K  |    3544 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     246    |     407    |    9201 K  |    9200 K  |
|       from large pool |       2    |      93    |    3544 K  |    3544 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      25    |      25    |      25    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      11    |      31    |    4908 K  |    4908 K  |
|       from large pool |       3    |      18    |    1875 K  |    1875 K  |
|       from small pool |       8    |      21    |    3033 K  |    3033 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-3/lra-listops/learnable.model
Evaluation Results
Loss: 1.64299
Accuracy: 0.37031
