GPU list: [0]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 512,
        "max_seq_len": 1024,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 4,
        "block_size": 32,
        "batch_size": 128,
        "density": 0.08,
        "mixed_precision": true,
        "random_seed": 3,
        "task": "lra-news1"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0009,
        "warmup": 80,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 200,
        "num_train_steps": 30000,
        "num_init_steps": 3000,
        "num_eval_steps": 200,
        "num_dense_train_steps": 10000,
        "patience": 10,
        "attn_loss_scale": 0.01,
        "skewness": 1.7,
        "distance": 1.3
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(512, 64)
        (position_embeddings): Embedding(1024, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=4, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([512, 64]), torch.Size([1024, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([4, 128]), torch.Size([4])]
num_parameter: 245252
Loaded ../Skyformer/data/lra_processed/lra-news1.train.pickle... size=120000
Loaded ../Skyformer/data/lra_processed/lra-news1.dev.pickle... size=7600
Loaded ../Skyformer/data/lra_processed/lra-news1.test.pickle... size=7600
accumu_steps=1
[tensor(24.3700, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(26.4235, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(23.2407, device='cuda:0', grad_fn=<MseLossBackward0>), tensor(24.8117, device='cuda:0', grad_fn=<MseLossBackward0>)]
best model saved: step =  199 dev accu =  tensor(0.5643, device='cuda:0')

Validation Results
Global Steps: 199
Valid Loss: 1.05557
Valid Accuracy: 0.56426
time stamp: 102.53051376342773
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-news1/module.model.transformer_0.mha.pattern.pickle
tensor([ 198,  759,  957,  528,   99,  627,  924,  594,  231,   66,  561,  363,
         858,  792,  495,  990,  132,  165,  825,  462,  396,  429,   33,  535,
         752,  210,  582,  693, 1023,  221,  934,  891,  765,  951,  536,  784,
         595,  626,  541,  944,  958,  989,  240,  519,  797,  952,  572,  913,
         573,  945,  297,  381,  939,  567,  753,  794,  856,  925,  956,  111,
         483,  764,  919,  472,  782,  208,  518,  605,  946,  497,  559,  156,
         900,  216,  774,  203,  358,  861,  954,  796,  920], device='cuda:0')
tensor(81, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_1.mha.pattern.pickle
tensor([ 825,  396,    0,  462,   66,  495,  528,  627, 1023,  429,   99,  858,
         693,  264,  165,  121,  803,  231,  792,  363,  330,  726,  561,  831,
        1017,  891,   25,  800,  957,   12,  384,  990,  297,  409,  812,  403,
         620,  505,  815,  249,  807,  633,  819,  569,  817,  473,  814,  793,
         824,   16,  512,   15,  480,   33,  239,  487,  398,  460,  127,  995,
         924,  639, 1011,  537,  816,  463,  494,   21,  672,    3,   96,  478,
         974,  660,  594,  281,  808,  399,  492,   14,  448], device='cuda:0')
tensor(81, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_2.mha.pattern.pickle
tensor([ 825,  165,   33,  660,  759,  891,  363,    0,  198,  132,  264,  462,
         594,  231,  330,  726,  990,  627,   99,  429,  561,  528,  924, 1023,
         396,   66,  183,  741,    1,   32,   55,  737,  473,  814,  297,  495,
         471,  750,  173,  421,  203,  358,  372,  651,  693,  191,  997,  180,
         645,  185,  805,  792,   23,  736,   50,  577,  727,  758,    5,  160,
         858,  139,  356,   38,  193,   39,  225,  827,  889,   43,  353,  375,
         747,  166,  197,  465,  558,  187,  869,  134,  196], device='cuda:0')
tensor(81, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_3.mha.pattern.pickle
tensor([ 759,  363,  693,  528,  924,  594,  396,  990,  462,  726,   66, 1023,
          33,    0,  297,  198,  368,  523,  957,  792,  165,   99,  429,  380,
         907,  825,  373,  683,  627,  366,  459,  330,  891,  132,  533,  688,
         264,  364,  395,   43,  353,  375,  747,  476,  910,  377,  811,   55,
         737,  540,  912,  213,  678,  695,  757,  858,   85,  674,   22,  704,
         764,  919,  112,  515,  471,  750,  495,   46,  449,  535,  752,  700,
         917,  406,  716,  190,  965,  370,  587,  412,  908], device='cuda:0')
tensor(81, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.1224679946899414
[]

Validation Results
Global Steps: 399
Valid Loss: 1.47036
Valid Accuracy: 0.36512
time stamp: 194.3414752483368
total training step (k): 30.0
total training time (s): 195.13934755325317
total training time (ms): 168819.7734375
peak memory usage (MB): 10632
allocated memory usage (MB): 17325323
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    4151 MB |   10632 MB |   16919 GB |   16915 GB |
|       from large pool |    4144 MB |   10604 MB |   16862 GB |   16858 GB |
|       from small pool |       7 MB |      32 MB |      56 GB |      56 GB |
|---------------------------------------------------------------------------|
| Active memory         |    4151 MB |   10632 MB |   16919 GB |   16915 GB |
|       from large pool |    4144 MB |   10604 MB |   16862 GB |   16858 GB |
|       from small pool |       7 MB |      32 MB |      56 GB |      56 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   10870 MB |   10870 MB |   10870 MB |       0 B  |
|       from large pool |   10836 MB |   10836 MB |   10836 MB |       0 B  |
|       from small pool |      34 MB |      34 MB |      34 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1096 MB |    1422 MB |    3045 GB |    3044 GB |
|       from large pool |    1092 MB |    1414 MB |    2988 GB |    2986 GB |
|       from small pool |       4 MB |      15 MB |      57 GB |      57 GB |
|---------------------------------------------------------------------------|
| Allocations           |     485    |     757    |  471352    |  470867    |
|       from large pool |      12    |      88    |  182312    |  182300    |
|       from small pool |     473    |     738    |  289040    |  288567    |
|---------------------------------------------------------------------------|
| Active allocs         |     485    |     757    |  471352    |  470867    |
|       from large pool |      12    |      88    |  182312    |  182300    |
|       from small pool |     473    |     738    |  289040    |  288567    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      47    |      47    |      47    |       0    |
|       from large pool |      30    |      30    |      30    |       0    |
|       from small pool |      17    |      17    |      17    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      24    |      44    |  234748    |  234724    |
|       from large pool |       9    |      17    |   64815    |   64806    |
|       from small pool |      15    |      31    |  169933    |  169918    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

dense memory(MB) : {} 16405788
dense step : {} 396
dense time : {} 186.20749735832214
sparse memory(MB) : {} 17320426
sparse step : {} 10
sparse_time : {} 1714027264.4169297
loading the best model from: ./checkpoints/checkpoints-3/lra-news1/tmp.model
