GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 32,
        "max_seq_len": 2048,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 64,
        "batch_size": 32,
        "density": 0.04,
        "mixed_precision": true,
        "random_seed": 4,
        "task": "lra-listops"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0006,
        "warmup": 1000,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 1000,
        "num_eval_steps": 62,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(32, 64)
        (position_embeddings): Embedding(2048, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([32, 64]), torch.Size([2048, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 280842
Loaded ../Skyformer/data/lra_processed/lra-listops.train.pickle... size=96000
Loaded ../Skyformer/data/lra_processed/lra-listops.dev.pickle... size=2000
Loaded ../Skyformer/data/lra_processed/lra-listops.test.pickle... size=2000
accumu_steps=1
[tensor([33.9272, 33.9272, 33.9272, 33.9272], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([36.4265, 36.4265, 36.4265, 36.4265], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([38.6646, 38.6646, 38.6646, 38.6646], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([40.5988, 40.5988, 40.5989, 40.5988], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.1711, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 2.25865
Valid Accuracy: 0.17112
time stamp: 830.0613811016083
[tensor([9.3406, 9.3407, 9.3407, 9.3407], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.0339, 10.0339, 10.0339, 10.0339], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.7644, 10.7644, 10.7644, 10.7644], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([11.4250, 11.4250, 11.4250, 11.4250], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.3435, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.73659
Valid Accuracy: 0.34350
time stamp: 1664.1971530914307
[tensor([3.0490, 3.0490, 3.0490, 3.0490], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.2255, 3.2256, 3.2256, 3.2256], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.4828, 3.4828, 3.4828, 3.4828], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.7135, 3.7135, 3.7135, 3.7135], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1499 dev accu =  tensor(0.3503, device='cuda:0')

Validation Results
Global Steps: 1499
Valid Loss: 1.73347
Valid Accuracy: 0.35030
time stamp: 2499.8563992977142
[tensor([1.4155, 1.4154, 1.4154, 1.4154], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4667, 1.4667, 1.4667, 1.4667], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.5911, 1.5911, 1.5911, 1.5911], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.6955, 1.6955, 1.6955, 1.6955], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1999 dev accu =  tensor(0.3627, device='cuda:0')

Validation Results
Global Steps: 1999
Valid Loss: 1.72371
Valid Accuracy: 0.36265
time stamp: 3338.6008336544037
[tensor([0.8033, 0.8033, 0.8033, 0.8033], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.8166, 0.8166, 0.8166, 0.8166], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.8897, 0.8897, 0.8897, 0.8897], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([0.9452, 0.9452, 0.9452, 0.9452], device='cuda:0',
       grad_fn=<GatherBackward>)]

Validation Results
Global Steps: 2499
Valid Loss: 1.72576
Valid Accuracy: 0.35938
time stamp: 4182.59534907341
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-listops/module.model.transformer_0.mha.pattern.pickle
tensor([726, 561, 693, 462, 495, 330, 165, 990, 957, 858, 396,  66, 264, 891,
        363, 231, 429,  33, 792, 759, 660,  99, 132, 528, 297, 825, 924,   0,
        566, 721, 198, 627, 594, 369, 555, 475, 878, 571, 881, 534],
       device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_1.mha.pattern.pickle
tensor([ 825,  231,  792,  363, 1023,  165,  891,   66,  462,  495,  759,   33,
         528,  330,  924,  726,  660,    0,   99,  957,  396,  264,  858,  198,
         561,  693,  990,  429,  297,  594,  132,  383, 1003,  171,  357,  463,
         494,  627,  767, 1015], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_2.mha.pattern.pickle
tensor([ 924,  231,  693,    0,  891,  561,  957,  594,  132,  198,  990,  726,
         264,  165,  627, 1023,  528,  330,  759,  660,   33,  495,  462,  363,
         792,   99,  858,  297,  825,  429,  396,   66,  572,  913,   40,  257,
         467,  622,  158,  964], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_3.mha.pattern.pickle
tensor([ 825,  132,  759,  297,  495,  429,  330, 1023,   33,  528,  561,  264,
         924,  660,  891,  462,  594,   66,  396,  858,  165,   99,  726,  627,
         198,  693,  792,  231,    0,  990,  957,  363,   57,  801,  537,  816,
         735, 1014,  761,  823], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.12203431129455566
[]

Validation Results
Global Steps: 2999
Valid Loss: 1.93442
Valid Accuracy: 0.30759
time stamp: 4792.591893196106
[]
best model saved: step =  3499 dev accu =  tensor(0.3635, device='cuda:0')

Validation Results
Global Steps: 3499
Valid Loss: 1.75328
Valid Accuracy: 0.36353
time stamp: 4837.506103515625
[]
best model saved: step =  3999 dev accu =  tensor(0.3661, device='cuda:0')

Validation Results
Global Steps: 3999
Valid Loss: 1.73351
Valid Accuracy: 0.36605
time stamp: 4883.288845539093
[]

Validation Results
Global Steps: 4499
Valid Loss: 1.73202
Valid Accuracy: 0.35396
time stamp: 4929.074237108231
[]

Validation Results
Global Steps: 4999
Valid Loss: 1.72400
Valid Accuracy: 0.35610
time stamp: 4974.295023679733
[]

Validation Results
Global Steps: 5499
Valid Loss: 1.70681
Valid Accuracy: 0.36240
time stamp: 5019.656912565231
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.70211
Valid Accuracy: 0.35648
time stamp: 5065.146136760712
[]

Validation Results
Global Steps: 6499
Valid Loss: 1.69921
Valid Accuracy: 0.35572
time stamp: 5110.292746067047
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.70612
Valid Accuracy: 0.36038
time stamp: 5155.717652082443
[]

Validation Results
Global Steps: 7499
Valid Loss: 1.69268
Valid Accuracy: 0.36303
time stamp: 5201.061826705933
[]

Validation Results
Global Steps: 7999
Valid Loss: 1.69449
Valid Accuracy: 0.36429
time stamp: 5246.947956085205
[]

Validation Results
Global Steps: 8499
Valid Loss: 1.69871
Valid Accuracy: 0.36568
time stamp: 5292.414619445801
[]

Validation Results
Global Steps: 8999
Valid Loss: 1.69458
Valid Accuracy: 0.36114
time stamp: 5337.632694721222
[]

Validation Results
Global Steps: 9499
Valid Loss: 1.69239
Valid Accuracy: 0.36202
time stamp: 5383.018451929092
[]

Validation Results
Global Steps: 9999
Valid Loss: 1.69105
Valid Accuracy: 0.36190
time stamp: 5428.870967388153
total training step (k): 10.0
total training time (s): 5428.871489286423
total training time (ms): 69833.81909179688
peak memory usage (MB): 12399
allocated memory usage (MB): 133625939
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7572 KB |   12399 MB |  130494 GB |  130494 GB |
|       from large pool |    3145 KB |   12391 MB |  129974 GB |  129974 GB |
|       from small pool |    4427 KB |      13 MB |     519 GB |     519 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7572 KB |   12399 MB |  130494 GB |  130494 GB |
|       from large pool |    3145 KB |   12391 MB |  129974 GB |  129974 GB |
|       from small pool |    4427 KB |      13 MB |     519 GB |     519 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   13530 MB |   13530 MB |   13530 MB |       0 B  |
|       from large pool |   13516 MB |   13516 MB |   13516 MB |       0 B  |
|       from small pool |      14 MB |      14 MB |      14 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1040 MB |    2061 MB |   41897 GB |   41896 GB |
|       from large pool |    1036 MB |    2056 MB |   41331 GB |   41330 GB |
|       from small pool |       3 MB |       7 MB |     565 GB |     565 GB |
|---------------------------------------------------------------------------|
| Allocations           |     246    |     407    |    9188 K  |    9187 K  |
|       from large pool |       2    |      93    |    3531 K  |    3531 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     246    |     407    |    9188 K  |    9187 K  |
|       from large pool |       2    |      93    |    3531 K  |    3531 K  |
|       from small pool |     244    |     381    |    5656 K  |    5656 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      25    |      25    |      25    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      12    |      31    |    4834 K  |    4834 K  |
|       from large pool |       3    |      18    |    1868 K  |    1868 K  |
|       from small pool |       9    |      19    |    2965 K  |    2965 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-4/lra-listops/learnable.model
Evaluation Results
Loss: 1.72294
Accuracy: 0.37031
