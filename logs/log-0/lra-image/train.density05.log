GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 2,
        "vocab_size": 256,
        "max_seq_len": 1024,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 32,
        "batch_size": 128,
        "density": 0.05,
        "mixed_precision": true,
        "random_seed": 0,
        "task": "lra-image"
    },
    {
        "batch_size": 512,
        "learning_rate": 0.0007,
        "warmup": 175,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 0,
        "num_eval_steps": 20,
        "num_dense_train_steps": 1000,
        "attn_loss_scale": 0.01
    }
]
attn compile
attn compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(256, 64)
        (position_embeddings): Embedding(1024, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([256, 64]), torch.Size([1024, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 160650
Loaded ../Skyformer/data/lra_processed/lra-image.train.pickle... size=45000
Loaded ../Skyformer/data/lra_processed/lra-image.dev.pickle... size=5000
Loaded ../Skyformer/data/lra_processed/lra-image.test.pickle... size=10000
accumu_steps=1
[tensor([13.3014, 13.3014, 13.3014, 13.3014], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([10.4467, 10.4467, 10.4467, 10.4467], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.3602, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 1.78522
Valid Accuracy: 0.36016
time stamp: 90.02480745315552
[tensor([3.4467, 3.4467, 3.4468, 3.4467], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([2.7141, 2.7141, 2.7141, 2.7141], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.4023, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.71500
Valid Accuracy: 0.40234
time stamp: 178.90352368354797
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
./pickle/lra-image/module.model.transformer_0.mha.pattern.pickle
tensor([   0,  594,  792,  858,  891,  363,   33,  165,  330,  231,  264,  957,
           8,  256,   99,  726,  924,  825,  660,    1,   32,   66,  561,  990,
          27,  864,  603,  882,    5,  160,   40,  257,  462,  627,  429,   18,
         576,  283,  872, 1023,  794,  856,  198,  274,  584,    7,  224,  600,
         786,   29,  928], device='cuda:0')
tensor(51, device='cuda:0')
block_attn compile
./pickle/lra-image/module.model.transformer_1.mha.pattern.pickle
tensor([ 528,  693,   66,  792,  825,  429,  462,  759,   99,  132,    0,  330,
         363,  924,  660,  990,  264,  627, 1023,  297,  495,  957,  396,  198,
          33,  561,  469,  686,  464,  526,  661,  692,  436,  653,  695,  757,
          10,  320,   85,  674,  341,  682,  366,  459,  891,  445,  941,  476,
         910,   89,  802], device='cuda:0')
tensor(51, device='cuda:0')
block_attn compile
total pattern searching time (s): 0.0048449039459228516
[]
best model saved: step =  1499 dev accu =  tensor(0.4174, device='cuda:0')

Validation Results
Global Steps: 1499
Valid Loss: 1.64446
Valid Accuracy: 0.41738
time stamp: 215.17465925216675
[]
best model saved: step =  1999 dev accu =  tensor(0.4250, device='cuda:0')

Validation Results
Global Steps: 1999
Valid Loss: 1.67881
Valid Accuracy: 0.42500
time stamp: 250.797354221344
[]

Validation Results
Global Steps: 2499
Valid Loss: 1.71987
Valid Accuracy: 0.42471
time stamp: 286.8104667663574
[]
best model saved: step =  2999 dev accu =  tensor(0.4413, device='cuda:0')

Validation Results
Global Steps: 2999
Valid Loss: 1.68808
Valid Accuracy: 0.44131
time stamp: 322.6717929840088
[]
best model saved: step =  3499 dev accu =  tensor(0.4439, device='cuda:0')

Validation Results
Global Steps: 3499
Valid Loss: 1.72747
Valid Accuracy: 0.44395
time stamp: 358.09800577163696
[]

Validation Results
Global Steps: 3999
Valid Loss: 1.80388
Valid Accuracy: 0.42510
time stamp: 393.67923974990845
[]

Validation Results
Global Steps: 4499
Valid Loss: 1.77996
Valid Accuracy: 0.42861
time stamp: 429.6469519138336
[]

Validation Results
Global Steps: 4999
Valid Loss: 1.87003
Valid Accuracy: 0.42021
time stamp: 465.4687602519989
[]

Validation Results
Global Steps: 5499
Valid Loss: 1.90983
Valid Accuracy: 0.42910
time stamp: 500.6268012523651
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.95053
Valid Accuracy: 0.42021
time stamp: 536.0782086849213
[]

Validation Results
Global Steps: 6499
Valid Loss: 1.95573
Valid Accuracy: 0.41660
time stamp: 571.8280484676361
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.96682
Valid Accuracy: 0.42676
time stamp: 607.8028059005737
[]

Validation Results
Global Steps: 7499
Valid Loss: 2.03866
Valid Accuracy: 0.42129
time stamp: 643.3922927379608
[]

Validation Results
Global Steps: 7999
Valid Loss: 2.05680
Valid Accuracy: 0.41602
time stamp: 679.5949831008911
[]

Validation Results
Global Steps: 8499
Valid Loss: 2.04758
Valid Accuracy: 0.42363
time stamp: 715.55202460289
[]

Validation Results
Global Steps: 8999
Valid Loss: 2.08248
Valid Accuracy: 0.41826
time stamp: 751.5448815822601
[]

Validation Results
Global Steps: 9499
Valid Loss: 2.06697
Valid Accuracy: 0.42363
time stamp: 787.2986400127411
[]

Validation Results
Global Steps: 9999
Valid Loss: 2.08501
Valid Accuracy: 0.41914
time stamp: 823.148206949234
total training step (k): 10.0
total training time (s): 823.148886680603
total training time (ms): 14485.536682128906
peak memory usage (MB): 7988
allocated memory usage (MB): 60443352
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8727 KB |    7988 MB |   59026 GB |   59026 GB |
|       from large pool |    6144 KB |    7982 MB |   58653 GB |   58653 GB |
|       from small pool |    2583 KB |      15 MB |     373 GB |     373 GB |
|---------------------------------------------------------------------------|
| Active memory         |    8727 KB |    7988 MB |   59026 GB |   59026 GB |
|       from large pool |    6144 KB |    7982 MB |   58653 GB |   58653 GB |
|       from small pool |    2583 KB |      15 MB |     373 GB |     373 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |    8612 MB |    8612 MB |    8612 MB |       0 B  |
|       from large pool |    8596 MB |    8596 MB |    8596 MB |       0 B  |
|       from small pool |      16 MB |      16 MB |      16 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   11753 KB |    1055 MB |   42120 GB |   42120 GB |
|       from large pool |   10240 KB |    1054 MB |   41706 GB |   41706 GB |
|       from small pool |    1513 KB |       4 MB |     414 GB |     414 GB |
|---------------------------------------------------------------------------|
| Allocations           |     144    |     228    |    5147 K  |    5147 K  |
|       from large pool |       2    |      47    |    1783 K  |    1783 K  |
|       from small pool |     142    |     206    |    3364 K  |    3363 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     144    |     228    |    5147 K  |    5147 K  |
|       from large pool |       2    |      47    |    1783 K  |    1783 K  |
|       from small pool |     142    |     206    |    3364 K  |    3363 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      30    |      30    |      30    |       0    |
|       from large pool |      22    |      22    |      22    |       0    |
|       from small pool |       8    |       8    |       8    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      24    |    2582 K  |    2582 K  |
|       from large pool |       2    |      12    |     660 K  |     660 K  |
|       from small pool |       8    |      18    |    1921 K  |    1921 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-0/lra-image/density05.model
Evaluation Results
Loss: 1.72255
Accuracy: 0.43740
