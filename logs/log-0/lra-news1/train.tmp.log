GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 512,
        "max_seq_len": 1024,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 4,
        "block_size": 32,
        "batch_size": 128,
        "density": 0.05,
        "mixed_precision": true,
        "random_seed": 0,
        "task": "lra-news1"
    },
    {
        "batch_size": 512,
        "learning_rate": 0.0007,
        "warmup": 80,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 200,
        "num_train_steps": 30000,
        "num_init_steps": 3000,
        "num_eval_steps": 200,
        "num_dense_train_steps": 100,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(512, 64)
        (position_embeddings): Embedding(1024, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=32, stride=32, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=4, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([512, 64]), torch.Size([1024, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([4, 128]), torch.Size([4])]
num_parameter: 245252
Loaded ../Skyformer/data/lra_processed/lra-news1.train.pickle... size=120000
Loaded ../Skyformer/data/lra_processed/lra-news1.dev.pickle... size=7600
Loaded ../Skyformer/data/lra_processed/lra-news1.test.pickle... size=7600
accumu_steps=1
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-news1/module.model.transformer_0.mha.pattern.pickle
tensor([660, 627, 924, 231,  33, 264, 759,  99, 792, 528, 462, 429, 363, 726,
        858, 693, 243, 615, 957,  66, 825, 764, 919, 297,  52, 641, 668, 916,
        495, 330,  35,  97, 468, 654,  51, 609, 561, 115, 611, 232, 263, 891,
        116, 643, 666, 852, 372, 651, 628, 659,  39], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_1.mha.pattern.pickle
tensor([297, 891, 132, 495, 627, 924, 693, 303, 489, 858, 155, 868, 231, 561,
        759, 396,   0, 154, 836, 629, 691,  33,  47, 481, 143, 484, 429, 137,
        292, 307, 617, 507, 879, 314, 841, 309, 681, 990, 149, 676, 305, 553,
        151, 740, 825, 499, 623, 316, 905, 135, 228], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_2.mha.pattern.pickle
tensor([858, 660, 726, 594, 429, 495, 231, 330,  66, 165, 730, 854, 132, 891,
        528, 666, 852, 442, 845, 396, 186, 837, 346, 842, 825, 506, 847, 182,
        709, 990, 410, 844, 662, 724, 246, 711, 826, 857, 338, 586, 627, 242,
        583,  99, 634, 851, 434, 589, 167, 229, 602], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
./pickle/lra-news1/module.model.transformer_3.mha.pattern.pickle
tensor([  66,  660,  528,  363,  594,   33,  990,  165,  759,  726,  924,  132,
          99,  462,  370,  587, 1023,  627,  372,  651,  596,  658,   80,  514,
         396,   50,  577,   43,  353,   34,   65,  530,  592,   48,  513,  368,
         523,  382,  971,   94,  962,  534,  720,   75,  354,   86,  706,  792,
         858,  604,  914], device='cuda:0')
tensor(51, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.133314847946167
best model saved: step =  199 dev accu =  tensor(0.4368, device='cuda:0')

Validation Results
Global Steps: 199
Valid Loss: 1.22356
Valid Accuracy: 0.43685
time stamp: 57.558128356933594
best model saved: step =  399 dev accu =  tensor(0.5615, device='cuda:0')

Validation Results
Global Steps: 399
Valid Loss: 1.04154
Valid Accuracy: 0.56150
time stamp: 92.13537549972534
best model saved: step =  599 dev accu =  tensor(0.5948, device='cuda:0')

Validation Results
Global Steps: 599
Valid Loss: 0.98807
Valid Accuracy: 0.59483
time stamp: 127.36693930625916
best model saved: step =  799 dev accu =  tensor(0.6113, device='cuda:0')

Validation Results
Global Steps: 799
Valid Loss: 0.95523
Valid Accuracy: 0.61128
time stamp: 162.18173837661743

Validation Results
Global Steps: 999
Valid Loss: 0.97348
Valid Accuracy: 0.60741
time stamp: 197.07130765914917
