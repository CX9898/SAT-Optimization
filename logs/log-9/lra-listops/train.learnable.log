GPU list: [0, 1, 2, 3]
[
    {
        "learn_pos_emb": true,
        "tied_weights": false,
        "embedding_dim": 64,
        "transformer_dim": 64,
        "transformer_hidden_dim": 128,
        "head_dim": 32,
        "num_head": 2,
        "num_layers": 4,
        "vocab_size": 32,
        "max_seq_len": 2048,
        "dropout_prob": 0.1,
        "attention_dropout": 0.1,
        "pooling_mode": "MEAN",
        "num_classes": 10,
        "block_size": 64,
        "batch_size": 32,
        "density": 0.04,
        "mixed_precision": true,
        "random_seed": 9,
        "task": "lra-listops"
    },
    {
        "batch_size": 128,
        "learning_rate": 0.0006,
        "warmup": 1000,
        "lr_decay": "linear",
        "weight_decay": 0,
        "eval_frequency": 500,
        "num_train_steps": 10000,
        "num_init_steps": 1000,
        "num_eval_steps": 62,
        "num_dense_train_steps": 1000,
        "patience": 10,
        "attn_loss_scale": 0.01
    }
]
attn_mask compile
attn_mask compile
attn_mask compile
attn_mask compile
DataParallel(
  (module): ModelForSC(
    (model): Model(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(32, 64)
        (position_embeddings): Embedding(2048, 64)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer_0): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_1): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_2): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (transformer_3): TransformerLayer(
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mha): Attention(
          (W_q): Linear(in_features=64, out_features=64, bias=True)
          (W_k): Linear(in_features=64, out_features=64, bias=True)
          (W_v): Linear(in_features=64, out_features=64, bias=True)
          (avg_pool): AvgPool2d(kernel_size=64, stride=64, padding=0)
          (MSEloss): MSELoss()
          (attn): CUDAMaskAttention()
          (ff): Linear(in_features=64, out_features=64, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (mlpblock): Sequential(
          (0): Linear(in_features=64, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Dropout(p=0.1, inplace=False)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): Dropout(p=0.1, inplace=False)
        )
      )
      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
    (seq_classifer): SCHead(
      (mlpblock): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=10, bias=True)
      )
    )
  )
)
parameter_size: [torch.Size([32, 64]), torch.Size([2048, 64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([32, 32]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64, 64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([64, 128]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64]), torch.Size([128]), torch.Size([10, 128]), torch.Size([10])]
num_parameter: 280842
Loaded ../Skyformer/data/lra_processed/lra-listops.train.pickle... size=96000
Loaded ../Skyformer/data/lra_processed/lra-listops.dev.pickle... size=2000
Loaded ../Skyformer/data/lra_processed/lra-listops.test.pickle... size=2000
accumu_steps=1
[tensor([32.9474, 32.9474, 32.9473, 32.9473], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([33.2166, 33.2166, 33.2166, 33.2166], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([34.5740, 34.5740, 34.5740, 34.5740], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([30.3377, 30.3377, 30.3377, 30.3377], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  499 dev accu =  tensor(0.1692, device='cuda:0')

Validation Results
Global Steps: 499
Valid Loss: 2.26291
Valid Accuracy: 0.16923
time stamp: 829.0659885406494
[tensor([8.9339, 8.9339, 8.9339, 8.9339], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.0283, 9.0282, 9.0282, 9.0283], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([9.4933, 9.4933, 9.4933, 9.4933], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([8.1973, 8.1973, 8.1973, 8.1973], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  999 dev accu =  tensor(0.3557, device='cuda:0')

Validation Results
Global Steps: 999
Valid Loss: 1.73201
Valid Accuracy: 0.35572
time stamp: 1658.69823884964
[tensor([2.8708, 2.8708, 2.8708, 2.8708], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([2.9069, 2.9069, 2.9069, 2.9069], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([3.0837, 3.0837, 3.0837, 3.0837], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([2.6667, 2.6667, 2.6667, 2.6667], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1499 dev accu =  tensor(0.3570, device='cuda:0')

Validation Results
Global Steps: 1499
Valid Loss: 1.72300
Valid Accuracy: 0.35698
time stamp: 2493.1804819107056
[tensor([1.3168, 1.3168, 1.3168, 1.3168], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.3361, 1.3361, 1.3361, 1.3361], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.4278, 1.4278, 1.4278, 1.4278], device='cuda:0',
       grad_fn=<GatherBackward>), tensor([1.2438, 1.2438, 1.2438, 1.2438], device='cuda:0',
       grad_fn=<GatherBackward>)]
best model saved: step =  1999 dev accu =  tensor(0.3582, device='cuda:0')

Validation Results
Global Steps: 1999
Valid Loss: 1.72901
Valid Accuracy: 0.35824
time stamp: 3334.5302913188934
module.model.transformer_0.mha.pattern saved
module.model.transformer_1.mha.pattern saved
module.model.transformer_2.mha.pattern saved
module.model.transformer_3.mha.pattern saved
./pickle/lra-listops/module.model.transformer_0.mha.pattern.pickle
tensor([ 297,  231,  990,  528,   99,  792,  198,  594,  726,  693,   66,  660,
         891,  627,  363,  858,  396,  330,  561,  825, 1023,  132,    0,  759,
         600,  786,  957,  462,   33,  264,  165,  495,  924,  429,  245,  679,
         534,  720,  242,  583], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_1.mha.pattern.pickle
tensor([ 726,    0,  990,  132,  594,   66,  759,  528,  495,  396,  924,  825,
        1023,  363,  627,  957,  297,   99,  693,  858,  891,  231,  561,   33,
         165,  198,  660,  429,  330,  792,  264,  606,  978,  598,  722,  462,
         135,  228,  732,  918], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_2.mha.pattern.pickle
tensor([ 693,  165,  462,  396,  198, 1023,  792,  528,  264,  330,  561,  594,
         990,  825,  957,    0,  297,  858,  891,  429,  924,  363,   66,  132,
         231,   33,  759,  627,  495,  726,   99,  660,  332,  394,  695,  757,
         209,  550,  433,  557], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
./pickle/lra-listops/module.model.transformer_3.mha.pattern.pickle
tensor([ 462,  231,  594,  693,  330,    0,  264,  957,  726,  165,  924,  396,
         363,  825,  198,  297,  891,  627,  990,  132,  429,  858,   99, 1023,
         759,   66,  792,   33,  660,  495,  561,  232,  263,   82,  578,  238,
         455,  370,  587,  199], device='cuda:0')
tensor(40, device='cuda:0')
block_attn_mask compile
total pattern searching time (s): 0.12211966514587402
[]

Validation Results
Global Steps: 2499
Valid Loss: 2.12920
Valid Accuracy: 0.27281
time stamp: 4041.6793687343597
[]

Validation Results
Global Steps: 2999
Valid Loss: 1.76022
Valid Accuracy: 0.33997
time stamp: 4087.0142941474915
[]

Validation Results
Global Steps: 3499
Valid Loss: 1.74107
Valid Accuracy: 0.35005
time stamp: 4132.184351444244
[]
best model saved: step =  3999 dev accu =  tensor(0.3663, device='cuda:0')

Validation Results
Global Steps: 3999
Valid Loss: 1.71895
Valid Accuracy: 0.36631
time stamp: 4178.387633323669
[]

Validation Results
Global Steps: 4499
Valid Loss: 1.70200
Valid Accuracy: 0.36152
time stamp: 4223.791433811188
[]

Validation Results
Global Steps: 4999
Valid Loss: 1.69847
Valid Accuracy: 0.36316
time stamp: 4269.276265144348
[]

Validation Results
Global Steps: 5499
Valid Loss: 1.69042
Valid Accuracy: 0.35219
time stamp: 4315.132529020309
[]

Validation Results
Global Steps: 5999
Valid Loss: 1.66915
Valid Accuracy: 0.35660
time stamp: 4360.5998249053955
[]

Validation Results
Global Steps: 6499
Valid Loss: 1.66581
Valid Accuracy: 0.36089
time stamp: 4404.445024967194
[]

Validation Results
Global Steps: 6999
Valid Loss: 1.66986
Valid Accuracy: 0.35774
time stamp: 4448.206977367401
[]

Validation Results
Global Steps: 7499
Valid Loss: 1.66269
Valid Accuracy: 0.36442
time stamp: 4492.004028558731
[]

Validation Results
Global Steps: 7999
Valid Loss: 1.66771
Valid Accuracy: 0.36038
time stamp: 4536.1932492256165
[]

Validation Results
Global Steps: 8499
Valid Loss: 1.66559
Valid Accuracy: 0.36001
time stamp: 4579.965742826462
[]

Validation Results
Global Steps: 8999
Valid Loss: 1.67029
Valid Accuracy: 0.36038
time stamp: 4623.518195152283
[]

Validation Results
Global Steps: 9499
Valid Loss: 1.66237
Valid Accuracy: 0.36177
time stamp: 4667.261345148087
[]

Validation Results
Global Steps: 9999
Valid Loss: 1.66602
Valid Accuracy: 0.36278
time stamp: 4710.785959482193
total training step (k): 10.0
total training time (s): 4710.786416769028
total training time (ms): 64349.65087890625
peak memory usage (MB): 12399
allocated memory usage (MB): 120883162
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    7572 KB |   12399 MB |  118049 GB |  118049 GB |
|       from large pool |    3145 KB |   12391 MB |  117540 GB |  117540 GB |
|       from small pool |    4427 KB |      13 MB |     509 GB |     509 GB |
|---------------------------------------------------------------------------|
| Active memory         |    7572 KB |   12399 MB |  118049 GB |  118049 GB |
|       from large pool |    3145 KB |   12391 MB |  117540 GB |  117540 GB |
|       from small pool |    4427 KB |      13 MB |     509 GB |     509 GB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   13530 MB |   13530 MB |   13530 MB |       0 B  |
|       from large pool |   13516 MB |   13516 MB |   13516 MB |       0 B  |
|       from small pool |      14 MB |      14 MB |      14 MB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |    1042 MB |    2001 MB |   42175 GB |   42174 GB |
|       from large pool |    1036 MB |    1996 MB |   41639 GB |   41638 GB |
|       from small pool |       5 MB |       7 MB |     536 GB |     536 GB |
|---------------------------------------------------------------------------|
| Allocations           |     246    |     407    |    8597 K  |    8597 K  |
|       from large pool |       2    |      93    |    3529 K  |    3529 K  |
|       from small pool |     244    |     381    |    5068 K  |    5068 K  |
|---------------------------------------------------------------------------|
| Active allocs         |     246    |     407    |    8597 K  |    8597 K  |
|       from large pool |       2    |      93    |    3529 K  |    3529 K  |
|       from small pool |     244    |     381    |    5068 K  |    5068 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |      32    |      32    |      32    |       0    |
|       from large pool |      25    |      25    |      25    |       0    |
|       from small pool |       7    |       7    |       7    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      12    |      31    |    4546 K  |    4546 K  |
|       from large pool |       3    |      18    |    1867 K  |    1867 K  |
|       from small pool |       9    |      21    |    2678 K  |    2678 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

loading the best model from: ./checkpoints/checkpoints-9/lra-listops/learnable.model
Evaluation Results
Loss: 1.70649
Accuracy: 0.36563
